{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = pd.read_csv('../data/arxiv_math.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_abstract(abstract):\n",
    "    abstract = abstract.replace('\\n', ' ') #remove new line characters\n",
    "    #abstract = re.sub('\\$.*?\\$', '', abstract)\n",
    "    #abstract = abstract.replace('such a', ' ').replace('previously known', ' ').replace('so called', ' ').replace('more general', ' ').replace('all the', ' ').replace('all these', ' ').replace('very challenging', ' ')\n",
    "    #abstract = abstract.replace('so-called', ' ').replace('well known', ' ').replace('particularly nice', ' ')\n",
    "    #abstract = abstract.replace('\"', '').replace(\"'\", '').replace('`','').replace('\\\\', '').replace('--', '-').replace('^*', '')\n",
    "    #abstract = re.sub('\\[.*?\\]', '', abstract)\n",
    "    #abstract = re.sub('\\s[a-zA-Z]{1}\\s', ' ', abstract)\n",
    "    #abstract = re.sub('\\s[0-9]+\\s', ' ', abstract)\n",
    "    #abstract = re.sub('\\(.*?\\)', '', abstract)\n",
    "    #abstract = re.sub('\\s[A-Z]{1}\\.\\s', ' ', abstract)\n",
    "    #abstract = abstract.replace('*', '')\n",
    "    #abstract = re.sub(' +', ' ', abstract)\n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv.abstract = arxiv.abstract.apply(lambda x : x.replace('\\n', ' '))\n",
    "arxiv.title = arxiv.title.apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_sentence(abstract):\n",
    "    try:\n",
    "        return abstract.split('.')[1]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'abstract', 'categories', 'created', 'id', 'doi'], dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def get_categories(categories):\n",
    "    try:  \n",
    "      return ' '.join(['__label__' + x[5:] for x in ast.literal_eval(categories) if x[:5] == 'math.'])\n",
    "    except:\n",
    "      return 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv['labels'] = arxiv.categories.apply(get_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv['first_sentence'] = arxiv.abstract.apply(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(arxiv, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../embeddings/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train.labels + ' ' + train.title + ' ' + train.abstract).dropna().to_csv('../embeddings/train.csv', index = False, header = False,quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./fasttext supervised -input cooking.train -output model_cooking -lr 0.5 -epoch 25 -wordNgrams 2 -bucket 200000 -dim 50 -loss one-vs-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_math_categories(categories):\n",
    "    import ast\n",
    "    return [x[5:] for x in ast.literal_eval(categories) if x[:5] == 'math.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv['math_categories'] = arxiv.categories.apply(get_math_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.fit(arxiv['math_categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['math_categories'] = train.categories.apply(get_math_categories)\n",
    "test['math_categories'] = test.categories.apply(get_math_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.transform(train.math_categories)\n",
    "y_test = mlb.transform(test.math_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.title + ' ' + train.abstract\n",
    "X_test = test.title + ' ' + test.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = ft.load_model('../embeddings/train_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FTVectorizer():\n",
    "    def __init__(self, ft_model):\n",
    "        self.model = ft_model\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        def get_sentence_vector(abstract):\n",
    "            return self.model.get_sentence_vector(abstract.replace('\\n', ' '))\n",
    "        return np.vstack(X.apply(get_sentence_vector).values)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline( steps = [\n",
    "                ('vectorizer', FTVectorizer(loaded_model)),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression())),\n",
    "                #('clf', OneVsRestClassifier(MultinomialNB())),\n",
    "                #('clf', OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=6, tol=None))),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', <__main__.FTVectorizer object at 0x7fc89a7bfd30>), ('clf', OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, hamming_loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    import numpy as np\n",
    "    '''\n",
    "    Compute the Hamming score (a.k.a. label-based accuracy) for the multi-label case\n",
    "    http://stackoverflow.com/q/32239577/395857\n",
    "    '''\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/float(len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss:  0.025520149176085007\n",
      "Hamming Score:  0.6125901965046706\n",
      "micro f1 score:  0.6792138591301771\n"
     ]
    }
   ],
   "source": [
    "print(\"Hamming Loss: \", hamming_loss(y_test, y_pred))\n",
    "print(\"Hamming Score: \", hamming_score(y_test, y_pred))\n",
    "print(\"micro f1 score: \", f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AC       0.71      0.57      0.63      1739\n",
      "          AG       0.79      0.72      0.75      6981\n",
      "          AP       0.76      0.69      0.72      6738\n",
      "          AT       0.65      0.53      0.59      1919\n",
      "          CA       0.57      0.44      0.50      2917\n",
      "          CO       0.77      0.71      0.74      7492\n",
      "          CT       0.62      0.51      0.56       926\n",
      "          CV       0.65      0.50      0.56      2160\n",
      "          DG       0.74      0.66      0.70      5530\n",
      "          DS       0.69      0.58      0.63      4097\n",
      "          FA       0.62      0.50      0.55      3766\n",
      "          GM       0.43      0.21      0.28       449\n",
      "          GN       0.62      0.43      0.51       614\n",
      "          GR       0.69      0.60      0.64      2745\n",
      "          GT       0.72      0.61      0.66      3044\n",
      "          HO       0.65      0.36      0.46       426\n",
      "          IT       0.89      0.85      0.87      5353\n",
      "          KT       0.60      0.41      0.48       790\n",
      "          LO       0.82      0.68      0.74      1510\n",
      "          MG       0.55      0.41      0.47      1332\n",
      "          MP       0.73      0.65      0.69     10953\n",
      "          NA       0.76      0.68      0.72      3082\n",
      "          NT       0.77      0.71      0.74      4834\n",
      "          OA       0.75      0.62      0.68      1759\n",
      "          OC       0.76      0.66      0.71      3856\n",
      "          PR       0.78      0.71      0.74      6665\n",
      "          QA       0.65      0.57      0.61      2851\n",
      "          RA       0.59      0.47      0.52      2133\n",
      "          RT       0.69      0.57      0.62      3263\n",
      "          SG       0.67      0.50      0.57      1253\n",
      "          SP       0.57      0.42      0.49      1302\n",
      "          ST       0.78      0.67      0.72      2451\n",
      "\n",
      "   micro avg       0.73      0.63      0.68    104930\n",
      "   macro avg       0.69      0.57      0.62    104930\n",
      "weighted avg       0.73      0.63      0.68    104930\n",
      " samples avg       0.69      0.69      0.66    104930\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(arxiv.labels + ' ' + arxiv.title + ' ' + arxiv.abstract).dropna().to_csv('../data/ftabstract_full.csv', index = False, header = False,quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = arxiv.abstract.apply(first_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts.to_csv('../data/abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_papers = pd.read_csv('../data/arxiv_math_2008.csv')\n",
    "new_papers.abstract = new_papers.abstract.apply(lambda x : x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ft.supervised('../data/ftabstract.csv', 'model', label_prefix='__label__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = \\\n",
    "\"We apply modern techniques of dyadic harmonic analysis to obtain sharp estimates for the Bergman projection in weighted Bergman spaces. Our main theorem focuses on the Bergman projection on Hartogs triangle. The estimates of the operator norm are in terms of a BekollÃ©-Bonami type constant. As an application of the results obtained, we give, for example, an upper bound for the Lp norm of the Bergman projection on the generalized Hartogs triangle Hm/n in C2. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AP', 'FA', 'CA', 'DS', 'CV', 'DG']]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict([abstract], 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['physics.optics', 'math-ph', 'math.MP']\n",
      "[['MP', 'AP', 'DS', 'DG', 'PR', 'QA']]\n",
      "There is currently a great deal of interest in the theoretical and practical possibility of cloaking objects from the observation by electromagnetic waves. The basic idea of these invisibility devices \\cite{glu1, glu2, le},\\cite{pss1} is to use anisotropic {\\it transformation media} whose permittivity and permeability $\\var^{\\lambda\\nu}, \\mu^{\\lambda\\nu}$, are obtained from the ones, $\\var_0^{\\lambda\\nu}, \\mu^{\\lambda\\nu}_0$, of isotropic media, by singular transformations of coordinates. In this paper we study electromagnetic cloaking in the time-domain using the formalism of time-dependent scattering theory. This formalism allows us to settle in an unambiguous way the mathematical problems posed by the singularities of the inverse of the permittivity and the permeability of the {\\it transformation media} on the boundary of the cloaked objects. We write Maxwell's equations in Schr\\\"odinger form with the electromagnetic propagator playing the role of the Hamiltonian. We prove that the electromagnetic propagator outside of the cloaked objects is essentially self-adjoint. Moreover, the unique self-adjoint extension is unitarily equivalent to the electromagnetic propagator in the medium $\\var_0^{\\lambda\\nu}, \\mu^{\\lambda\\nu}_0$. Using this fact, and since the coordinate transformation is the identity outside of a ball, we prove that the scattering operator is the identity. Our results give a rigorous proof that the construction of \\cite{glu1, glu2, le}, \\cite{pss1} perfectly cloaks passive and active devices from observation by electromagnetic waves. Furthermore, we prove cloaking for general anisotropic materials. In particular, our results prove that it is possible to cloak objects inside general crystals.\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(new_papers.loc[i, 'categories'])\n",
    "print(classifier.predict([new_papers.loc[i, 'abstract']], 6))\n",
    "print(new_papers.loc[i, 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ft.skipgram('../data/ftabstract.csv', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lie',\n",
       " 'let',\n",
       " 'paper',\n",
       " 'volatility',\n",
       " 'advantages',\n",
       " '\\\\\\\\gamma',\n",
       " '$\\\\\\\\ell$',\n",
       " 'jet',\n",
       " 'sufficient',\n",
       " 'momenta',\n",
       " 'orientations',\n",
       " 'did',\n",
       " 'trying',\n",
       " 'supremum',\n",
       " 'viewed',\n",
       " 'p-cyclotomic',\n",
       " '$A_0$',\n",
       " 'his',\n",
       " 'allowing',\n",
       " 'irreversible',\n",
       " 'saddle-node',\n",
       " 'B$',\n",
       " 'du',\n",
       " 'top',\n",
       " 'convenient',\n",
       " '$f',\n",
       " 'BPS',\n",
       " 'routing',\n",
       " 'nothing',\n",
       " 'Kazhdan',\n",
       " 'identification',\n",
       " 'K\\\\,',\n",
       " 'iteration',\n",
       " 'dual\\\\,',\n",
       " 'transparent',\n",
       " 'Probab',\n",
       " 'provide',\n",
       " 'representative',\n",
       " 'NP',\n",
       " 'monomials\\\\,',\n",
       " 'foundation',\n",
       " 'times\\\\,',\n",
       " '$G',\n",
       " 'Gelman',\n",
       " 'arrays',\n",
       " 'choose',\n",
       " 'transmission',\n",
       " 'Veronese',\n",
       " 'multivariate',\n",
       " 'nilpotent\\\\,',\n",
       " 'context\\\\,',\n",
       " 'encoding',\n",
       " 'strengthened',\n",
       " 'surface\\\\,',\n",
       " 'holomorphically',\n",
       " 'discover',\n",
       " 'Goldie',\n",
       " 'categorification',\n",
       " 'work\\\\,',\n",
       " 'curves',\n",
       " 'trivially',\n",
       " 'Chen',\n",
       " 'hold',\n",
       " 'definable',\n",
       " 'homogenization',\n",
       " 'axioms',\n",
       " 'representations\\\\,',\n",
       " 'Oka',\n",
       " 'noncommutativity',\n",
       " 'possessing',\n",
       " 'deriving',\n",
       " 'degenerate',\n",
       " 'leading',\n",
       " 'spinor',\n",
       " 'abundance',\n",
       " 'autoequivalences',\n",
       " 'ways',\n",
       " 'systems',\n",
       " 'non-Euclidean',\n",
       " 'Schr\"odinger',\n",
       " 'c\\\\,',\n",
       " 'regular',\n",
       " 'records',\n",
       " 'prolongation',\n",
       " 'trilinear',\n",
       " 'time-independent',\n",
       " 'TQFT',\n",
       " 'studies',\n",
       " '$S^n$',\n",
       " 'include:',\n",
       " 'transmitter',\n",
       " 'cases\\\\,',\n",
       " 'ensemble\\\\,',\n",
       " 'hypersurface\\\\,',\n",
       " 'timelike',\n",
       " '2-sphere',\n",
       " 'wideband',\n",
       " 'diagonalizable',\n",
       " 'cross-section',\n",
       " 'popular',\n",
       " 'decreasing',\n",
       " 'measure)',\n",
       " 'G_n',\n",
       " \"Igusa's\",\n",
       " 'Dixmier',\n",
       " 'fake',\n",
       " '[16]',\n",
       " 'proving',\n",
       " 'vorticity',\n",
       " 'narrow',\n",
       " 'improving',\n",
       " 'return',\n",
       " 'bundle',\n",
       " 'doubly',\n",
       " 'reviews',\n",
       " 'projective\\\\,',\n",
       " 'energy-momentum',\n",
       " 'recovering',\n",
       " 'stay',\n",
       " 'quasi',\n",
       " 'moments',\n",
       " '(n-1)-dimensional',\n",
       " 'nonequivalent',\n",
       " 'geometry',\n",
       " 'matches',\n",
       " 'car',\n",
       " '$\\\\\\\\chi$',\n",
       " 'ordinals',\n",
       " 'LP',\n",
       " 'rewritten',\n",
       " 'only\\\\,',\n",
       " 'constraints\\\\,',\n",
       " 'gaps',\n",
       " 'imaging',\n",
       " 'compatibility',\n",
       " 'bundle\\\\,',\n",
       " 'antisymmetric',\n",
       " 'essential',\n",
       " 'origin\\\\,',\n",
       " 'processes\\\\,',\n",
       " 'localization',\n",
       " 'article',\n",
       " 'phase-space',\n",
       " 'investigations',\n",
       " 'involved\\\\,',\n",
       " 'R)',\n",
       " 'complexes\\\\,',\n",
       " 'A-modules',\n",
       " 'half',\n",
       " 'strengthening',\n",
       " 'instanton',\n",
       " 'prototypical',\n",
       " 'isometries',\n",
       " 'asymptotics',\n",
       " 'Kottwitz',\n",
       " 'symmetrization',\n",
       " 'multi-dimensional',\n",
       " '$\\\\\\\\alpha$',\n",
       " 'otherwise\\\\,',\n",
       " 'states',\n",
       " 'references',\n",
       " 'discontinuities',\n",
       " 'really',\n",
       " 'distinguish',\n",
       " '$\\\\\\\\epsilon>0$',\n",
       " 'Monge-Ampere',\n",
       " '2-category',\n",
       " 'quadrics',\n",
       " 'Lucas',\n",
       " 'capacity',\n",
       " 'implies\\\\,',\n",
       " 'confirm',\n",
       " 'comprehensive',\n",
       " 'extended',\n",
       " 'indicates',\n",
       " 'appendix',\n",
       " 'monad',\n",
       " 'says',\n",
       " 'spectra\\\\,',\n",
       " 'admissibility',\n",
       " 'flow\\\\,',\n",
       " 'established\\\\,',\n",
       " 'function',\n",
       " '3/2',\n",
       " 'avoiding',\n",
       " 'closed',\n",
       " 'memoryless',\n",
       " 'computationally',\n",
       " 'verification',\n",
       " 'Kac-Moody',\n",
       " 'persistence',\n",
       " 'ideas',\n",
       " 'intrinsic',\n",
       " 'prove',\n",
       " \"Szab\\\\\\\\'o\",\n",
       " 'modulo',\n",
       " 'and',\n",
       " 'consequently',\n",
       " '\"quantum',\n",
       " 'unbiased',\n",
       " 'Lelong',\n",
       " 'geometries',\n",
       " 'invariant',\n",
       " 'formally',\n",
       " 'infinity)',\n",
       " 'computation\\\\,',\n",
       " 'rules\\\\,',\n",
       " 'finite-time',\n",
       " \"Green's\",\n",
       " 'fulfill',\n",
       " 'experiment',\n",
       " 'slopes',\n",
       " 'Joyce',\n",
       " 'pulses',\n",
       " 'its',\n",
       " '$0',\n",
       " 'Proceedings',\n",
       " 'trends',\n",
       " 'Previously\\\\,',\n",
       " 'loops',\n",
       " 'crossing',\n",
       " 'polylogarithms',\n",
       " 'diversity-multiplexing',\n",
       " 'element',\n",
       " 'apparent',\n",
       " 'mirror',\n",
       " 'A$',\n",
       " 'just',\n",
       " 'solved',\n",
       " 'vectorial',\n",
       " 'investigates',\n",
       " '(and',\n",
       " '$\\\\\\\\infty$',\n",
       " 'additional',\n",
       " 'hierarchies',\n",
       " '3-folds',\n",
       " 'founded',\n",
       " '$n\\\\\\\\times',\n",
       " 'discrete-time',\n",
       " 'suited',\n",
       " '(J',\n",
       " 'measure-preserving',\n",
       " 'de',\n",
       " 'Large',\n",
       " 'against',\n",
       " 'Roughly',\n",
       " 'refine',\n",
       " 'exterior',\n",
       " 'target',\n",
       " 'Frobenius-Schur',\n",
       " 'module',\n",
       " 'combines',\n",
       " 'dynamical',\n",
       " 'translations',\n",
       " 'but',\n",
       " 'possibilities',\n",
       " 'oscillator\\\\,',\n",
       " 'unions',\n",
       " 'Within',\n",
       " 'topological',\n",
       " 'Coleman',\n",
       " 'minimally',\n",
       " 'H\\\\\\\\\"older',\n",
       " '(with',\n",
       " 'contracted',\n",
       " 'T$\\\\,',\n",
       " '$g\\\\\\\\geq',\n",
       " 'towers',\n",
       " 'holds',\n",
       " 'quartics',\n",
       " 'CM',\n",
       " 'formulations',\n",
       " '$T$\\\\,',\n",
       " 'offered',\n",
       " 'quadratic',\n",
       " 'noted',\n",
       " 'adapt',\n",
       " 'association',\n",
       " 'augmented',\n",
       " 'quotients\\\\,',\n",
       " 'packet',\n",
       " 'parametrix',\n",
       " 'circular',\n",
       " 'entities',\n",
       " 'conical',\n",
       " 'ALE',\n",
       " 'cardinal',\n",
       " '\\\\\\\\infty}',\n",
       " 'observability',\n",
       " 'Rieffel',\n",
       " 'genera',\n",
       " 'unify',\n",
       " '{\\\\\\\\Bbb',\n",
       " 'modifications',\n",
       " 'tending',\n",
       " 'isometric',\n",
       " 'undeformed',\n",
       " 'orbital',\n",
       " 'inducing',\n",
       " 'established',\n",
       " 'sum-free',\n",
       " 'C',\n",
       " 'k',\n",
       " 'Quantum',\n",
       " 'Fermat',\n",
       " 'polynomial-time',\n",
       " '(The',\n",
       " '2007',\n",
       " 'equivalent:',\n",
       " 'Cohen-Macaulayness',\n",
       " 'rate',\n",
       " 'refinements',\n",
       " 'Kadomtsev-Petviashvili',\n",
       " 'separated',\n",
       " 'level\\\\,',\n",
       " 'junctions',\n",
       " 'turbo',\n",
       " 'specializations',\n",
       " 'role',\n",
       " 'semidirect',\n",
       " 'coding',\n",
       " 'versions',\n",
       " 'Lee',\n",
       " 'technique\\\\,',\n",
       " 'supercompact',\n",
       " 'again',\n",
       " 'edges\\\\,',\n",
       " 'science',\n",
       " 'congruent',\n",
       " 'Dynkin',\n",
       " 'truncation',\n",
       " 'going',\n",
       " 'decode',\n",
       " 'decompose',\n",
       " 'serves',\n",
       " 'increasing',\n",
       " 'propositional',\n",
       " 'signal-to-noise',\n",
       " 'optics',\n",
       " 'Goppa',\n",
       " 'death',\n",
       " 'Motzkin',\n",
       " '$\\\\\\\\mathcal{A}$',\n",
       " 'seen',\n",
       " 'orbits\\\\,',\n",
       " 'moduli',\n",
       " 'Smale',\n",
       " 'Coxeter',\n",
       " 'solving',\n",
       " 'contexts',\n",
       " 'Hopf-Galois',\n",
       " 'unified',\n",
       " 'der',\n",
       " 'object',\n",
       " 'underlying',\n",
       " 'n\\\\,',\n",
       " 'cocompact',\n",
       " 'S^2$',\n",
       " 'secondary',\n",
       " 'Gelfand\\\\,',\n",
       " 'factor',\n",
       " 'subject\\\\,',\n",
       " 'Denote',\n",
       " 'A$\\\\,',\n",
       " 'operator-valued',\n",
       " 'Math',\n",
       " 'inverted',\n",
       " 'to',\n",
       " 'ingredient',\n",
       " 'coincide',\n",
       " '$\\\\\\\\mu',\n",
       " 'q-analogue',\n",
       " 'volume-preserving',\n",
       " 'equivariant',\n",
       " '$C^\\\\\\\\infty$',\n",
       " '(This',\n",
       " 'zeros',\n",
       " 's',\n",
       " 'posterior',\n",
       " 'Assume',\n",
       " 'occur',\n",
       " 'proposed\\\\,',\n",
       " '\\\\\\\\exp',\n",
       " '$Y',\n",
       " 'errors\\\\,',\n",
       " 'Hard',\n",
       " 'channel\\\\,',\n",
       " 'recurrences',\n",
       " 'nonempty',\n",
       " 'Viterbi',\n",
       " '\\\\\\\\Omega\\\\,',\n",
       " 'Lawson',\n",
       " 'B_k',\n",
       " '$A_n$',\n",
       " 'gains',\n",
       " 'laced',\n",
       " 'Hilbert-Schmidt',\n",
       " 'orbifolds\\\\,',\n",
       " 'imbedding',\n",
       " 'extending',\n",
       " 'likelihood',\n",
       " 'draw',\n",
       " 'jumps',\n",
       " '4$',\n",
       " 'Gagliardo-Nirenberg',\n",
       " 'field\\\\,',\n",
       " 'distributions\\\\,',\n",
       " 'equivalence',\n",
       " 'nearby',\n",
       " 'extensions',\n",
       " 'C^N',\n",
       " 'abelian',\n",
       " 'reviewed',\n",
       " 'available',\n",
       " 'procedure\\\\,',\n",
       " 'practice',\n",
       " 'p\\\\,',\n",
       " 'involution',\n",
       " 'functor',\n",
       " '\\\\\\\\delta',\n",
       " 'quantity',\n",
       " 'per',\n",
       " 'characterisation',\n",
       " 'descents',\n",
       " 'fit',\n",
       " 'hypothesis\\\\,',\n",
       " 'jets',\n",
       " 'communications',\n",
       " 'bialgebras',\n",
       " 'convection',\n",
       " 'unit',\n",
       " 'irrationality',\n",
       " 'excellent',\n",
       " 'section\\\\,',\n",
       " 'octonionic',\n",
       " 'extracted',\n",
       " 'revised',\n",
       " 'assignment',\n",
       " 'epsilon',\n",
       " 'distinct',\n",
       " 'purely',\n",
       " 'Cayley',\n",
       " 'weak',\n",
       " 'growth\\\\,',\n",
       " 'choosing',\n",
       " 'ingredients',\n",
       " 'empirical',\n",
       " 'bases',\n",
       " 'four\\\\,',\n",
       " 'discrete',\n",
       " 'Maslov',\n",
       " 'equal',\n",
       " 'greatest',\n",
       " 'forcing',\n",
       " 'regimes\\\\,',\n",
       " 'bridges',\n",
       " 'N',\n",
       " 'July',\n",
       " 'costs',\n",
       " 'Karu',\n",
       " 'examples',\n",
       " 'reflexive',\n",
       " 'combinatorially',\n",
       " 'evaluated',\n",
       " 'number',\n",
       " 'Osserman',\n",
       " 'Groebner',\n",
       " 'alone',\n",
       " 'identifying',\n",
       " 'D)$',\n",
       " '(no',\n",
       " 'W',\n",
       " 'transforming',\n",
       " 'so\\\\,',\n",
       " 'multiplier',\n",
       " 'classes\\\\,',\n",
       " 'y',\n",
       " 'standing',\n",
       " 'Typical',\n",
       " 'lax',\n",
       " 'rewriting',\n",
       " 'embeds',\n",
       " 'HO',\n",
       " '$\\\\\\\\R^n$',\n",
       " 'context',\n",
       " 'Teichmuller',\n",
       " 'twofold',\n",
       " 'lists',\n",
       " 'Monge-Amp\\\\\\\\`ere',\n",
       " 'introducing',\n",
       " '$Q$\\\\,',\n",
       " 'extensive',\n",
       " 'be',\n",
       " \"Jensen's\",\n",
       " 'boundary\\\\,',\n",
       " 'Results',\n",
       " 'Szego',\n",
       " 'deduce',\n",
       " 'smooth',\n",
       " 'Kazhdan--Lusztig',\n",
       " \"Voiculescu's\",\n",
       " 'Tauberian',\n",
       " 'between',\n",
       " '\\\\\\\\in',\n",
       " 'complexification',\n",
       " 'Ein',\n",
       " 'filiform',\n",
       " 'their',\n",
       " 'processing',\n",
       " 'quadruples',\n",
       " 'multiply',\n",
       " 'G',\n",
       " 'gases',\n",
       " 'metric',\n",
       " 'limit',\n",
       " 'n}',\n",
       " 'b)',\n",
       " 'coordinates',\n",
       " 'k\\\\,',\n",
       " 'coincidence',\n",
       " 'percolation\\\\,',\n",
       " 'paper)',\n",
       " 'detects',\n",
       " 'conformal',\n",
       " 'Laplacian\\\\,',\n",
       " 'i',\n",
       " 'letter\\\\,',\n",
       " 'formalization',\n",
       " 'scales',\n",
       " 'Teichmueller',\n",
       " 'akin',\n",
       " 'acting',\n",
       " 'monotone',\n",
       " 'backward',\n",
       " 'Levi-Civita',\n",
       " 'inductively',\n",
       " 'denominator',\n",
       " 'artinian',\n",
       " 'done',\n",
       " 'encountered',\n",
       " 'Gordon',\n",
       " 'tuples',\n",
       " 'hyperkahler',\n",
       " 'environment',\n",
       " 'specifying',\n",
       " 'adopt',\n",
       " 'relevance',\n",
       " ':=',\n",
       " 'bivector',\n",
       " 'polyhedral',\n",
       " 'representing',\n",
       " 'criteria',\n",
       " '\\\\\\\\log',\n",
       " 'group)',\n",
       " 'loop',\n",
       " 'policies',\n",
       " 'prerequisites',\n",
       " 'coloured',\n",
       " 'motion\\\\,',\n",
       " 'Also\\\\,',\n",
       " 'these\\\\,',\n",
       " 'orderings',\n",
       " 'saddle',\n",
       " 'deep',\n",
       " 'foliation',\n",
       " 'set)',\n",
       " 'Set',\n",
       " 'act',\n",
       " 'stably',\n",
       " 'based',\n",
       " 'matrix',\n",
       " 'Max',\n",
       " 'Gelfand',\n",
       " 'RT$',\n",
       " 'resources',\n",
       " 'compactness',\n",
       " \"Godel's\",\n",
       " 'though',\n",
       " 'plants',\n",
       " 'multiuser',\n",
       " 'non-minimal',\n",
       " 'truncated',\n",
       " 'T)',\n",
       " 'dominant',\n",
       " 'multiplicity\\\\,',\n",
       " 'maxima',\n",
       " 'contravariant',\n",
       " 'strips',\n",
       " 'derives',\n",
       " 'starts',\n",
       " 'exceptional',\n",
       " 'effective',\n",
       " 'fields\\\\,',\n",
       " 'usage',\n",
       " '$B$',\n",
       " 'Bott',\n",
       " 'arc',\n",
       " \"it's\",\n",
       " 'Feller',\n",
       " 'necessary',\n",
       " 'STST/0606441]',\n",
       " 'holonomy',\n",
       " 'morphisms\\\\,',\n",
       " 'cards',\n",
       " 'Equivalently\\\\,',\n",
       " 'Del',\n",
       " 'Though',\n",
       " 'problem:',\n",
       " '$S^2$',\n",
       " 'improved',\n",
       " 'book',\n",
       " 'rings',\n",
       " 'endomorphisms',\n",
       " 'Leray',\n",
       " 'check',\n",
       " '(super)algebras',\n",
       " 'poorly',\n",
       " '${\\\\\\\\mathfrak',\n",
       " '2-bridge',\n",
       " 'else',\n",
       " 'matching',\n",
       " 'unable',\n",
       " 'language',\n",
       " 'boundedly',\n",
       " 'decision',\n",
       " 'normalization',\n",
       " 'self-avoiding',\n",
       " 'q-Bernoulli',\n",
       " 'governed',\n",
       " 'empty\\\\,',\n",
       " 'surgeries',\n",
       " 'aspherical',\n",
       " 'stream',\n",
       " 'communicate',\n",
       " 'Schubert',\n",
       " 'my',\n",
       " 'parts\\\\,',\n",
       " '1$)',\n",
       " 'strengthen',\n",
       " 'reduced',\n",
       " '3-spheres',\n",
       " 'trees',\n",
       " 'filling',\n",
       " 'shell',\n",
       " 'separable',\n",
       " 'partial',\n",
       " 'centered',\n",
       " 'serve',\n",
       " 'not',\n",
       " 'elements',\n",
       " 'vertical',\n",
       " 'introduced',\n",
       " 'any',\n",
       " '\\\\\\\\nu',\n",
       " 'tasks',\n",
       " 'boundary',\n",
       " 'invertible',\n",
       " 'cobordisms',\n",
       " 'made',\n",
       " 'sentence',\n",
       " 'deformation\\\\,',\n",
       " 'employs',\n",
       " 'samples',\n",
       " 'generally',\n",
       " 'wall',\n",
       " 'Julia',\n",
       " 'low',\n",
       " 'paper:',\n",
       " 'examines',\n",
       " 'oscillatory',\n",
       " 'cooperative',\n",
       " 'quasiprojective',\n",
       " 'nonsymmetric',\n",
       " 'angle',\n",
       " 'lie',\n",
       " 'criterion',\n",
       " 'horizons',\n",
       " 'hypercomplex',\n",
       " 'couples',\n",
       " 'logic',\n",
       " 'Even',\n",
       " 'Tychonoff',\n",
       " 'congruence',\n",
       " 'rescaled',\n",
       " 'opposite',\n",
       " 'ways\\\\,',\n",
       " 'making',\n",
       " 'descending',\n",
       " 'aim',\n",
       " 'thing',\n",
       " 'Radon',\n",
       " 'realizes',\n",
       " 'robustness',\n",
       " 'discs',\n",
       " 'furthermore',\n",
       " 'prices',\n",
       " 'coboundary',\n",
       " 'discrete\\\\,',\n",
       " 'continues',\n",
       " 'classification',\n",
       " 'brings',\n",
       " 'adjacency',\n",
       " '$h$-vector',\n",
       " 'second-order',\n",
       " 'Anderson',\n",
       " 'spacelike',\n",
       " '$\\\\\\\\sigma$',\n",
       " 'concrete',\n",
       " 'spectrally',\n",
       " 'divided',\n",
       " 'spike',\n",
       " 'MPe',\n",
       " 'put',\n",
       " 'shifts',\n",
       " 'words\\\\,',\n",
       " 'constitute',\n",
       " 'D',\n",
       " 'Li',\n",
       " 'them\\\\,',\n",
       " 'Carlitz',\n",
       " 'bigger',\n",
       " 'track',\n",
       " 'pulse',\n",
       " 'biholomorphic',\n",
       " 'Riemann-Hilbert',\n",
       " 'chemical',\n",
       " '$S',\n",
       " 'max-plus',\n",
       " 'longest',\n",
       " 'tradeoff',\n",
       " 'simulations',\n",
       " 'sheaf',\n",
       " 'rational',\n",
       " 'performs',\n",
       " 'Dirichlet\\\\,',\n",
       " 'improvements',\n",
       " 'complementary',\n",
       " 'determinant\\\\,',\n",
       " 'endow',\n",
       " 'quandle',\n",
       " 'integrated',\n",
       " 'germs',\n",
       " 'exponents\\\\,',\n",
       " 'result:',\n",
       " 'fibered',\n",
       " 'Moufang',\n",
       " 'monotonicity',\n",
       " 'discovered',\n",
       " '(over',\n",
       " 'bent',\n",
       " 'explored',\n",
       " 'induced',\n",
       " 'descriptions',\n",
       " 'modelled',\n",
       " 'belief',\n",
       " 'omega',\n",
       " 'noiseless',\n",
       " 'bounds',\n",
       " 'Wronskian',\n",
       " 'spline',\n",
       " 'enhanced',\n",
       " 'easier',\n",
       " 'bipartite',\n",
       " 'Methods',\n",
       " 'hierarchical',\n",
       " 'prescribed',\n",
       " 'demonstrated',\n",
       " 'partition',\n",
       " 'handling',\n",
       " 'girth',\n",
       " 'considering',\n",
       " 'holds\\\\,',\n",
       " 'mind',\n",
       " 'ITi',\n",
       " \"Serre's\",\n",
       " 'conventional',\n",
       " 'After',\n",
       " 'Gauss-Manin',\n",
       " 'bring',\n",
       " 'density',\n",
       " 'Simple',\n",
       " 'SLE',\n",
       " 'Topics',\n",
       " 'outer',\n",
       " 'note',\n",
       " 'CDMA',\n",
       " 'Chapter',\n",
       " 'roles',\n",
       " 'NT',\n",
       " 'ii)',\n",
       " 'polynomials\\\\,',\n",
       " 'spins',\n",
       " '3',\n",
       " 'subsets',\n",
       " 'multivalued',\n",
       " 'CMC',\n",
       " 'Therefore',\n",
       " 'an',\n",
       " 'Virasoro',\n",
       " 'operads',\n",
       " 'cochain',\n",
       " 'motivating',\n",
       " 'first\\\\,',\n",
       " 'pegs',\n",
       " 'proof\\\\,',\n",
       " 'approximate',\n",
       " 'L\\\\,',\n",
       " 'poles',\n",
       " 'Building',\n",
       " 'structures',\n",
       " 'fixes',\n",
       " 'formulated',\n",
       " 'Wang',\n",
       " 'polygon',\n",
       " 'inviscid',\n",
       " 'AGg',\n",
       " 'biorthogonal',\n",
       " 'lifting',\n",
       " 'programming',\n",
       " 'Theory',\n",
       " 'scenario',\n",
       " '$\\\\\\\\phi',\n",
       " 'coefficient',\n",
       " 'calibration',\n",
       " 'matchings',\n",
       " 'few',\n",
       " 'odd-dimensional',\n",
       " 'still',\n",
       " 'excursion',\n",
       " 'seven',\n",
       " 'row',\n",
       " 'diagrammatic',\n",
       " 'natural',\n",
       " 'assumes',\n",
       " 'occurrences',\n",
       " 'R-matrices',\n",
       " 'walks',\n",
       " 'all\\\\,',\n",
       " 'non-hyperbolic',\n",
       " 'generated\\\\,',\n",
       " 'generalize',\n",
       " 'process\\\\,',\n",
       " 'Reynolds',\n",
       " 'parametrizations',\n",
       " 'semi-simple',\n",
       " 'Severi',\n",
       " 'sectional',\n",
       " 'away',\n",
       " 'Let',\n",
       " 'absence',\n",
       " 'frequency',\n",
       " 'are:',\n",
       " 'curve',\n",
       " 'nth',\n",
       " 'groupoids',\n",
       " 'transversality',\n",
       " 'monoidal',\n",
       " 'g)',\n",
       " '\\\\\\\\cite',\n",
       " 'non-coherent',\n",
       " 'will',\n",
       " 'V$',\n",
       " 'contour',\n",
       " 'situation\\\\,',\n",
       " 'Lagrange',\n",
       " 'wedge',\n",
       " 'diffeomorphic',\n",
       " 'R^n\\\\,',\n",
       " 'inscribed',\n",
       " 'space\\\\,',\n",
       " 'freeness',\n",
       " 'additivity',\n",
       " '(A',\n",
       " 'intrinsically',\n",
       " 'X',\n",
       " 'conjecture',\n",
       " '\\\\\\\\to',\n",
       " 'graded',\n",
       " '6\\\\,',\n",
       " 'extracting',\n",
       " 'zeta-functions',\n",
       " '\\\\\\\\theta',\n",
       " 'scenarios',\n",
       " 'self-linking',\n",
       " 'finitely',\n",
       " 'roughly',\n",
       " 'cores',\n",
       " 'conductor',\n",
       " '(where',\n",
       " 'definitions',\n",
       " 'representatives',\n",
       " 'hitting',\n",
       " 'others\\\\,',\n",
       " 'suspension',\n",
       " 'exists\\\\,',\n",
       " 'Here\\\\,',\n",
       " 'investigate',\n",
       " 'Various',\n",
       " 'Batyrev',\n",
       " 'Yang-Baxter',\n",
       " '$u$',\n",
       " 'revisited',\n",
       " 'it\\\\,',\n",
       " 'maps\\\\,',\n",
       " 'Galton-Watson',\n",
       " 'subbundle',\n",
       " 'equivalences',\n",
       " 'one)',\n",
       " 'E$',\n",
       " 'wealth',\n",
       " 'scientific',\n",
       " 'Sol',\n",
       " 'situated',\n",
       " 'implicitly',\n",
       " 'cluster',\n",
       " 'background\\\\,',\n",
       " 'conformally',\n",
       " 'self-contained',\n",
       " 'interest',\n",
       " '$A^*:V',\n",
       " 'Systems',\n",
       " 'sense)',\n",
       " 'ring',\n",
       " 'leaves',\n",
       " 'choice',\n",
       " 'Z$',\n",
       " 'during',\n",
       " 'distribution',\n",
       " 'Consequently',\n",
       " 'monomorphisms',\n",
       " 'f\\\\,',\n",
       " '$(W\\\\,S)$',\n",
       " 'nuclear',\n",
       " 'Jacobian',\n",
       " 'graph\\\\,',\n",
       " 'automaton',\n",
       " 'y)',\n",
       " 'Finslerian',\n",
       " '$H$\\\\,',\n",
       " '$V',\n",
       " 'Mathieu',\n",
       " 'L$',\n",
       " 'quasi-coherent',\n",
       " 'Shilov',\n",
       " 'this',\n",
       " 'retract',\n",
       " 'strategy',\n",
       " 'statistics\\\\,',\n",
       " 'rectangles',\n",
       " 'recall',\n",
       " 'pre-Lie',\n",
       " 'non-archimedean',\n",
       " 'Numerical',\n",
       " 'designs',\n",
       " '$f$',\n",
       " 'Hamiltonians',\n",
       " 'blow',\n",
       " 'R^d',\n",
       " 'arbitrary',\n",
       " 'Airy',\n",
       " '$F_k$',\n",
       " 'modes',\n",
       " 'annihilating',\n",
       " 'Dirichlet',\n",
       " 'counterpart',\n",
       " 'K$',\n",
       " '$m\\\\\\\\geq',\n",
       " 'collector',\n",
       " 'collapsing',\n",
       " 'traffic',\n",
       " 'm$',\n",
       " 'Algebra',\n",
       " 'analogue',\n",
       " 'Hochschild',\n",
       " 'G/P',\n",
       " 'non-trivial',\n",
       " 'monomial',\n",
       " 'Souslin',\n",
       " 'amalgamated',\n",
       " 'infinitely',\n",
       " 'focuses',\n",
       " '[',\n",
       " 'vertices\\\\,',\n",
       " 'crystals\\\\,',\n",
       " 'compactification',\n",
       " 'une',\n",
       " 'exponent',\n",
       " 'picture',\n",
       " 'quasitriangular',\n",
       " 'move',\n",
       " 'even',\n",
       " 'Among',\n",
       " 'ansatz',\n",
       " 'nets',\n",
       " 'turning',\n",
       " 'actually',\n",
       " 'desired',\n",
       " 'defect',\n",
       " '19th',\n",
       " 'Yau',\n",
       " ...}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
